<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" />
    <meta name="google-site-verification" content="mzyi5h_x1DvmnvvOynztP5h3mA2mdBpUjfhySMB9NNI" />
    <!-- Google Tag Manager -->
    <script>
      (function (w, d, s, l, i) {
        w[l] = w[l] || [];
        w[l].push({ 'gtm.start': new Date().getTime(), event: 'gtm.js' });
        var f = d.getElementsByTagName(s)[0],
          j = d.createElement(s),
          dl = l != 'dataLayer' ? '&l=' + l : '';
        j.async = true;
        j.src = 'https://www.googletagmanager.com/gtm.js?id=' + i + dl;
        f.parentNode.insertBefore(j, f);
      })(window, document, 'script', 'dataLayer', 'GTM-NS48J6H');
    </script>
    <!-- End Google Tag Manager -->
    <title>Lorna Mugambi | Publications</title>
    <meta name="author" content="Lorna Mugambi" />
    <link rel="icon" href="assets/imgs/logo3.png" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link href="https://fonts.googleapis.com/css2?family=Public+Sans:wght@400;500;700&display=swap" rel="stylesheet" />
    <script src="https://cdn.tailwindcss.com?plugins=forms,container-queries"></script>
    <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/6.4.0/css/all.min.css" />
    <style type="text/tailwindcss">
      :root {
        --primary-color: #dda0dd;
        --secondary-color: #f8f0fb;
        --background-color: #f9f9f9;
        --text-primary: #333333;
        --text-secondary: #666666;
        --accent-color: #ffdab9;
        --accent-pink: #ffb6c1;
      }
      body {
        font-family: 'Public Sans', sans-serif;
        background-color: var(--background-color);
        color: var(--text-primary);
      }
    </style>
  </head>
  <body>
    <div class="flex min-h-screen">
      <aside class="bg-white fixed left-0 top-0 h-screen w-80 p-6 shadow-lg hidden lg:flex flex-col">
        <div class="flex flex-col items-center text-center">
          <img src="assets/imgs/myprofile.jpg" alt="Lorna Mugambi" class="rounded-full w-36 h-36 mx-auto mb-4 object-cover border-4 border-[var(--accent-pink)]" />
          <h1 class="text-2xl font-bold text-[var(--text-primary)]">Lorna Mugambi</h1>
          <p class="text-base text-[var(--text-secondary)]">Researcher at DSAIL</p>
          <p class="text-base text-[var(--text-secondary)]">Nairobi, Kenya</p>
        </div>
        <nav class="mt-8 flex-grow">
          <ul class="space-y-2">
            <li><a class="w-full text-left px-4 py-3 rounded-lg text-base font-semibold transition-colors duration-200 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]" href="index.html">Home</a></li>
            <li><a class="w-full text-left px-4 py-3 rounded-lg text-base font-semibold transition-colors duration-200 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]" href="updates.html">Updates</a></li>
            <li><a class="w-full text-left px-4 py-3 rounded-lg text-base font-semibold transition-colors duration-200 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)] bg-[var(--secondary-color)] text-[var(--primary-color)]" href="publications.html">Publications</a></li>
            <li><a class="w-full text-left px-4 py-3 rounded-lg text-base font-semibold transition-colors duration-200 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]" href="tutorials.html">Tutorials</a></li>
            <li><a class="w-full text-left px-4 py-3 rounded-lg text-base font-semibold transition-colors duration-200 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]" href="blogs.html">Blogs</a></li>
          </ul>
        </nav>
        <div class="flex justify-center space-x-4 mt-6">
          <a class="text-gray-500 hover:text-[var(--primary-color)] transition-colors duration-200" href="https://github.com/lornamugambi" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.757-1.333-1.757-1.089-.745.083-.729.083-.729 1.205.085 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.108-.775.418-1.305.762-1.604-2.665-.304-5.467-1.334-5.467-5.93 0-1.31.469-2.381 1.236-3.221-.124-.303-.536-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.655 1.653.243 2.874.119 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
          </a>
          <a class="text-gray-500 hover:text-[var(--primary-color)] transition-colors duration-200" href="https://www.linkedin.com/in/lorna-mugambi/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
            <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-10h3v10zm-1.5-11.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.784 1.764-1.75 1.764zm13.5 11.268h-3v-5.604c0-1.337-.026-3.061-1.866-3.061-1.868 0-2.154 1.459-2.154 2.967v5.698h-3v-10h2.881v1.367h.041c.401-.761 1.379-1.563 2.839-1.563 3.038 0 3.6 2.001 3.6 4.604v5.592z"/></svg>
          </a>
        </div>
      </aside>

      <div class="flex flex-col w-full">
        <header class="bg-white shadow-md lg:hidden sticky top-0 z-10">
          <div class="mx-auto px-4 sm:px-6 lg:px-8">
            <div class="flex items-center justify-between h-16">
              <div class="flex items-center">
                <a href="index.html" class="text-xl font-bold text-[var(--primary-color)]">Lorna Mugambi</a>
              </div>
              <div class="flex lg:hidden">
                <button id="mobile-menu-button" class="inline-flex items-center justify-center p-2 rounded-md text-gray-400 hover:text-white hover:bg-gray-700 focus:outline-none focus:ring-2 focus:ring-inset focus:ring-white" aria-controls="mobile-menu" aria-expanded="false">
                  <span class="sr-only">Open main menu</span>
                  <svg class="block h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M4 6h16M4 12h16m-7 6h7" /></svg>
                  <svg class="hidden h-6 w-6" xmlns="http://www.w3.org/2000/svg" fill="none" viewBox="0 0 24 24" stroke="currentColor" aria-hidden="true"><path stroke-linecap="round" stroke-linejoin="round" stroke-width="2" d="M6 18L18 6M6 6l12 12" /></svg>
                </button>
              </div>
            </div>
          </div>
          <div class="hidden lg:hidden" id="mobile-menu">
            <div class="px-2 pt-2 pb-3 space-y-1 sm:px-3">
              <a href="index.html" class="block px-3 py-2 rounded-md text-base font-medium text-gray-700 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]">Home</a>
              <a href="updates.html" class="block px-3 py-2 rounded-md text-base font-medium text-gray-700 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]">Updates</a>
              <a href="publications.html" class="block px-3 py-2 rounded-md text-base font-medium text-gray-700 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]">Publications</a>
              <a href="tutorials.html" class="block px-3 py-2 rounded-md text-base font-medium text-gray-700 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]">Tutorials</a>
              <a href="blogs.html" class="block px-3 py-2 rounded-md text-base font-medium text-gray-700 hover:bg-[var(--secondary-color)] hover:text-[var(--primary-color)]">Blogs</a>
            </div>
          </div>
        </header>

        <main class="flex-grow lg:ml-80 p-8">
          <section class="mb-12" id="publications">
            <h2 class="text-3xl font-bold text-[var(--primary-color)] mb-6">Publications</h2>
            <!-- Begin original publications content (tables preserved) -->
            <div class="bg-transparent">
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:100%;vertical-align:middle">
                    <heading>2025</heading>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle">
                    <div class="one"><img src='assets/imgs/11060566-fig-3-source-small.gif' width="320" height="auto"></div>
                  </td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://ieeexplore.ieee.org/document/11060566"><papertitle>Deployment and Evaluation of the Autonomous Monitoring of Insects (AMI) System for Ecosystem Health Assessment in Kenya</papertitle></a><br>
                    <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <strong>Lorna Mugambi</strong>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>  <br>
                    <em>2025 IST-Africa Conference (IST-Africa)</em>, May, 2025.<br>
                    <a href="https://doi.org/10.23919/IST-Africa67297.2025.11060566"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Class Insecta make up about 40 % of the terrestrial animal biomass. Due to biomass size and incredible adaptability to various stresses in the environment such as changes in temperature and predators, insects can be used as ecosystems health indicator species when closely monitored. This paper details the deployment of an autonomous insect monitoring system, and the development and implementation of an image-processing based insect count algorithm. The Autonomous Monitoring of Insect (AMI) system was developed by the UK Centre for Ecology and Hydrology and deployed at the Dedan Kimathi University Wildlife Conservancy in Kenya. The insect-count algorithm was able to count insects, averaging 10 per night over two months, with peaks between 8.00 pm and midnight. Initial challenges included images with overlapping insects, which affected accuracy, highlighting the need for more refined count algorithms. Future work will expand to species classification and behavioural analysis, particularly moths. By providing continuous and autonomous data, the AMI system offers a scalable tool to assess biodiversity trends which inform ecosystem management in Kenya.</p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/dino_rhd.png' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://www.mdpi.com/2313-433X/11/4/97"><papertitle>Self-Supervised Multi-Task Learning for the Detection and Classification of RHD-Induced Valvular Pathology</papertitle></a><br>
                    <strong>Lorna Mugambi</strong>, <a href="https://ciirawamaina.com">Ciira wa Maina</a>, <a href="https://health.uct.ac.za/cape-heart-institute/contacts/liesl-zuhlke">Liesl Zühlke</a>   <br>
                    <em>Journal of Imaging</em>, March, 2025.<br>
                    <a href="http://dx.doi.org/10.3390/jimaging11040097"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Rheumatic heart disease (RHD) poses a significant global health challenge, necessitating improved diagnostic tools. This study investigated the use of self-supervised multi-task learning for automated echocardiographic analysis, aiming to predict echocardiographic views, diagnose RHD conditions, and determine severity. We compared two prominent self-supervised learning (SSL) methods: DINOv2, a vision-transformer-based approach known for capturing implicit features, and simple contrastive learning representation (SimCLR), a ResNet-based contrastive learning method recognised for its simplicity and effectiveness. Both models were pre-trained on a large, unlabelled echocardiogram dataset and fine-tuned on a smaller, labelled subset. DINOv2 achieved accuracies of 92% for view classification, 98% for condition detection, and 99% for severity assessment. SimCLR demonstrated good performance as well, achieving accuracies of 99% for view classification, 92% for condition detection, and 96% for severity assessment. Embedding visualisations, using both Uniform Manifold Approximation Projection (UMAP) and t-distributed Stochastic Neighbor Embedding (t-SNE), revealed distinct clusters for all tasks in both models, indicating the effective capture of the discriminative features of the echocardiograms. This study demonstrates the potential of using self-supervised multi-task learning for automated echocardiogram analysis, offering a scalable and efficient approach to improving RHD diagnosis, especially in resource-limited settings.</p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr><td style="padding:20px;width:100%;vertical-align:middle"><heading>2024</heading></td></tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/architecture of the model.png' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://www.researchgate.net/publication/387109957_Automated_ECG_Image_Classification_with_InceptionV3"><papertitle>Automated ECG Image Classification with InceptionV3</papertitle></a><br>
                    <a href="#">Antony M. Gitau</a>, <a href="#">Victor Ruto</a>, <a href="#/">Yuri Njathi</a> <strong>Lorna Mugambi</strong>, <a href="#">Victory A. Sitati</a>, <a href="#">Austin Kaburia</a> <br>
                    <em>Computing in Cardiology Conference</em>, December, 2024.<br>
                    <a href="http://dx.doi.org/10.22489/CinC.2024.498"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Despite the rise of digital electrocardiogram (ECG) technology, paper-based ECGs continue to be prevalent, especially in underrepresented and underserved communities. This paper presents the DSAIL team's participation in the George B. Moody PhysioNet Challenge 2024 to develop an open-source algorithm for classifying ECG images. We fine-tuned a pre-trained InceptionV3 model on the PTB-XL dataset, comprising 21,799 12-lead ECG recordings, supplemented with synthetic ECG images from the ECG-Image-Kit. The model was trained using 80% of these images, reserving 20% for validation. Our choice of the InceptionV3 architecture leverages its capability to effectively capture local and global features, which is crucial for the inherent variability in ECG image patterns. The model achieved a validation macro F-measure score of 0.429 on a dataset accessible only to the organizers, securing 6th place on the official classification leaderboard. However, the algorithm struggled with mobile phone images of stained, deteriorated, and cleaned ECGs, yielding a low F-score of 0.08. In contrast, it performed significantly better on color scans of clean and deteriorated paper ECGs, achieving an F-score of 0.5. Although further improvements are necessary, neural network-based algorithms demonstrate promising potential for enhancing access to ECG-based diagnosis and cardiac care.</p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/gejusta_workshop.jpg' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://riojournal.com/article/138833/"><papertitle>The DSAIL-GeJuSTA Data Science Education Workshop: Designing a Data Science Curriculum for the African Continent</papertitle></a><br>
                    <strong>Lorna Mugambi</strong>, <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>, <a href="https://ovus00.github.io/">Suvodeep Mazumdar</a><br>
                    <em>Workshop Report: Research Ideas and Outcomes</em>, October, 2024.<br>
                    <a href="https://doi.org/10.3897/rio.10.e138833"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>The DSAIL-GeJuSTA Data Science Education Workshop was a joint initiative by the Centre for Data Science and Artificial Intelligence (DSAIL) and Gender Justice in STEM Research in Africa (GeJUSTA). GeJUSTA is a programme funded by the International Development Research Centre (IDRC) that is working towards increasing the representation of women in STEM. The workshop was held on 9 November 2023, during the 7th DeKUT International Conference on Science, Technology, Innovation and Entrepreneurship (STI&E) at Dedan Kimathi University of Technology (DeKUT). The conference ran from 8-10 November 2023. The event successfully convened 31 participants. The composition of the attendees was diverse, ranging from data-science educators, industry participants using data science, researchers who use data science and students in a myriad of courses, including engineering and pharmacy. The primary focus of the workshop was to have a discussion with the attendees and share practices around designing data-science curriculum, strategies for achieving gender equity in data-science education, addressing new technological challenges in education and fostering multidisciplinary approaches to data-science education. This report encapsulates the collective vision of the workshop participants, whose contributions have set the stage for progressive strides in data-science education.</p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr><td style="padding:20px;width:100%;vertical-align:middle"><heading>2023</heading></td></tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/gejusta.png' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://repository.dkut.ac.ke:8080/xmlui/handle/123456789/8422"><papertitle>Analysis of women representation in STEM in Africa</papertitle></a><br>
                    <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <strong>Lorna Mugambi</strong>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>  <br>
                    <em>7th DeKUT International Conference on Science, Technology, Innovation and Entrepreneurship</em>, November, 2023.<br>
                    <a href="https://repository.dkut.ac.ke:8080/xmlui/handle/123456789/8422"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Girls and women have consistently been underrepresented in most Science, Technology, Engineering, and Mathematics (STEM) professions, necessitating research. There is a need to define and execute measures and policies to help reduce this gap. The Centre for Data Science and Artificial Intelligence (DSAIL), in collaboration with Gender Justice in STEM Research in Africa (GeJuSTA), is conducting studies to analyse a the representation of women in STEM in Africa. The study will be used to guide the development of policies and curricula aimed at bridging the gap of women representation in STEM. The methods used in this study are analysing the genders of members of staffs in STEM faculties from African universities; analysing the genders of STEM-papers’ authors from African universities and; conducting literature review to evaluate existing measures that have been put in place to encourage and enable women to join STEM professions. Preliminary results show that women are underrepresented in STEM fields in Africa.</p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/dsailboard.jpeg' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10293682"><papertitle>The use of Open-Source Boards for Data Collection and Machine Learning in Remote Deployments</papertitle></a><br>
                    <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <strong>Lorna Mugambi</strong>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>  <br>
                    <em>2023 IEEE AFRICON</em>, September.<br>
                    <a href="https://doi.org/10.1109/AFRICON55910.2023.10293682"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Machine learning is being adopted in many walks of life to solve various problems. This is being driven by development of robust machine learning algorithms, availability of large datasets and low-cost computation resources. Some machine learning applications require deployment of devices off-the-grid for data collection and processing. Such applications require development of systems that can operate autonomously during their deployment. This paper presents how some open-source boards have been leveraged for off-grid data collection and machine learning. Advancement in technology has seen development of low-cost and low-power open-source boards that can be interfaced with a wide array of sensors for data collection and can perform computation processes. The boards are finding wide applications in data collection and machine learning initiatives. A wide array of open source boards exists in the market. The boards can generally be divided into micro controllers, single board computers and field programmable gate arrays. These boards have different properties in terms of processing capabilities, power consumption, and communication interfaces and features. For off-grid data collection and machine learning tasks, resources such as power and network for communication are limited in most cases. These factors should be considered when choosing boards for off-grid deployment tasks. The boards chosen should optimise the use of these resources while meeting the processing capabilities required for the tasks at hand.</p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/annotated.gif' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://ieeexplore.ieee.org/abstract/document/10293724"><papertitle>Efficient Camera Trap Image Annotation Using YOLOv5</papertitle></a><br>
                    <a href="#">Yuri Njathi</a>, <a href="#">Lians Wanjiku</a>, <strong>Lorna Mugambi</strong>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>  <br>
                    <em>2023 IEEE AFRICON</em>, September.<br>
                    <a href="https://doi.org/10.1109/AFRICON55910.2023.10293724"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Using camera traps to acquire wildlife images is becoming more common within conservancies. The information provided by these camera traps enhances understanding of wildlife behaviour and population patterns. The detection and counting of animals present in each of the captured images is valuable information as it can be used to guide conservation efforts. Manual annotation of these wildlife images is a tedious painful process. It is becoming more common to use tools that either use AI to annotate camera trap datasets or use AI to aid in annotation. These AI tools are usually trained on species endemic to a particular region. The ability to fine-tune such models to species endemic to one's particular region is important to save much of the time conservationists manually look through the misclassified images. In this paper, we present a case study where we used a YOLOv5 object detection model trained to detect the presence and count the number of impala and other animals from a dataset collected by researchers at the Dedan Kimathi University of Technology Conservancy. We analyze the results of the AI's performance with respect to a manually annotated dataset. The model was able to annotate 72% of the dataset at a human level of accuracy. The work here shows promise with regard to time spent labelling camera trap images by leveraging the presence of particular species to auto-annotate a majority of the dataset.</p>
                  </td>
                </tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr><td style="padding:20px;width:100%;vertical-align:middle"><heading>2022</heading></td></tr>
              </tbody></table>
              <table style="width:100%;border:0px;border-spacing:0px;border-collapse:separate;margin-right:auto;margin-left:auto;"><tbody>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/rhd-pipeline.gif' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://ieeexplore.ieee.org/abstract/document/9845657"><papertitle>Towards AI Based Diagnosis of Rheumatic Heart Disease: Data Annotation and View Classification</papertitle></a><br>
                    <strong>Lorna Mugambi</strong>, <a href="https://ciirawamaina.com">Ciira wa Maina</a>, <a href="https://health.uct.ac.za/cape-heart-institute/contacts/liesl-zuhlke">Liesl Zühlke</a>  <br>
                    <em>2022 IST-Africa Conference (IST-Africa)</em>, May, 2022.<br>
                    <a href="https://doi.org/10.23919/IST-Africa56635.2022.9845657"><span><i class="fas fa-scroll"></i></span>Paper</a>
                    <p></p>
                    <p>Rheumatic Heart Disease is a cardiovascular disease highly prevalent in developing countries partially because of inadequate healthcare infrastructure to treat Group A streptococcus pharyngitis and thereafter diagnose and document every case of Acute Rheumatic Fever, the immune-mediated antecedent of rheumatic heart disease. Secondary antibiotic treatment with penicillin injections after a diagnosis of Acute Rheumatic Fever and Rheumatic Heart Disease is used to prevent further attacks of Strep A, preferably prior to any heart valve damage. Echocardiographic screening for early detection of Rheumatic Heart Disease has been proposed as a method to improve outcomes but it is time-consuming, costly and few people are skilled enough to reach a correct diagnosis. Machine Learning is an emerging tool in analysing medical images; our aim is to automate the screening process of diagnosing rheumatic heart disease. In this paper, we present a web application to be used to label echocardiography data. These labelled data can then be used to develop machine learning models that can classify echocardiographic views of the heart and damaged valves from the echocardiograms.</p>
                  </td>
                </tr>
                <tr>
                  <td style="padding:20px;width:25%;vertical-align:middle"><div class="one"><img src='assets/imgs/dsailporinidataset.jpeg' width="320" height="auto"></div></td>
                  <td style="padding:20px;width:75%;vertical-align:middle">
                    <a href="https://data.mendeley.com/datasets/6mhrhn7rxc/6"><papertitle>DSAIL-Porini: Annotated camera trap images of wildlife species from a conservancy in Kenya</papertitle></a><br>
                    <strong>Lorna Mugambi</strong>, <a href="https://kiariegabriel.github.io/">Gabriel Kiarie</a>, <a href="https://kabi23.github.io/">Jason Kabi</a>, <a href="http://ciirawamaina.com/">Ciira wa Maina</a>  <br>
                    <em>Mendeley Data</em>, March 2022.<br>
                    <a href="https://data.mendeley.com/datasets/6mhrhn7rxc/6"><span><i class="fas fa-scroll"></i></span>Dataset</a>
                    <p></p>
                    <p>This dataset has camera trap images of wildlife species from a conservancy in Kenya and their annotation. They are based on the Raspberry Pi 2, Raspberry Pi Zero and the OpenMV Cam H7 devices. The camera traps were deployed in the conservancy from June 2021 to December 2021. We have 6 categories of grazing mammals in this dataset; Burchell's zebra, Defassa waterbuck, bushbuck, Common warthog, impala and the Syke's monkey.</p>
                  </td>
                </tr>
              </tbody></table>
            </div>
            <!-- End original publications content -->
          </section>
        </main>

        <footer class="bg-white mt-12 p-8 border-t border-gray-200">
          <div class="max-w-7xl mx-auto text-center">
            <h3 class="text-2xl font-bold text-[var(--primary-color)] mb-4">Get in Touch</h3>
            <div class="flex justify-center space-x-6 mb-6">
              <a class="text-gray-500 hover:text-[var(--primary-color)] transition-colors duration-200" href="https://github.com/lornamugambi" target="_blank" rel="noopener noreferrer" aria-label="GitHub">
                <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="currentColor"><path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.757-1.333-1.757-1.089-.745.083-.729.083-.729 1.205.085 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.108-.775.418-1.305.762-1.604-2.665-.304-5.467-1.334-5.467-5.93 0-1.31.469-2.381 1.236-3.221-.124-.303-.536-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.655 1.653.243 2.874.119 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/></svg>
              </a>
              <a class="text-gray-500 hover:text-[var(--primary-color)] transition-colors duration-200" href="https://www.linkedin.com/in/lorna-mugambi/" target="_blank" rel="noopener noreferrer" aria-label="LinkedIn">
                <svg xmlns="http://www.w3.org/2000/svg" width="32" height="32" viewBox="0 0 24 24" fill="currentColor"><path d="M19 0h-14c-2.761 0-5 2.239-5 5v14c0 2.761 2.239 5 5 5h14c2.762 0 5-2.239 5-5v-14c0-2.761-2.238-5-5-5zm-11 19h-3v-10h3v10zm-1.5-11.268c-.966 0-1.75-.79-1.75-1.764s.784-1.764 1.75-1.764 1.75.79 1.75 1.764-.784 1.764-1.75 1.764zm13.5 11.268h-3v-5.604c0-1.337-.026-3.061-1.866-3.061-1.868 0-2.154 1.459-2.154 2.967v5.698h-3v-10h2.881v1.367h.041c.401-.761 1.379-1.563 2.839-1.563 3.038 0 3.6 2.001 3.6 4.604v5.592z"/></svg>
              </a>
            </div>
            <p class="text-sm text-[var(--text-secondary)]">© 2025 Lorna Mugambi. All rights reserved.</p>
          </div>
        </footer>
      </div>
    </div>

    <script>
      const mobileMenuButton = document.getElementById('mobile-menu-button');
      const mobileMenu = document.getElementById('mobile-menu');
      if (mobileMenuButton && mobileMenu) {
        const menuIconOpen = mobileMenuButton.querySelector('svg:first-child');
        const menuIconClose = mobileMenuButton.querySelector('svg:last-child');
        mobileMenuButton.addEventListener('click', () => {
          const isExpanded = mobileMenuButton.getAttribute('aria-expanded') === 'true';
          mobileMenuButton.setAttribute('aria-expanded', String(!isExpanded));
          mobileMenu.classList.toggle('hidden');
          if (menuIconOpen && menuIconClose) {
            menuIconOpen.classList.toggle('hidden');
            menuIconClose.classList.toggle('hidden');
          }
        });
      }
    </script>
  </body>
  </html>